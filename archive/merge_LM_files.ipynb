{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lossmap_paths(path, file_name_base):\n",
    "\n",
    "    n_jobs = int(subprocess.check_output(f'find {path}/job* -maxdepth 0 -type d | wc -l', shell=True))\n",
    "    n_jobs_succeeded = int(subprocess.check_output(f'find {path}/job* -maxdepth 0 -type d -not -empty | wc -l', shell=True))\n",
    "    \n",
    "    job_files_list = []\n",
    "    for i in range(n_jobs):\n",
    "        current_file_path = (subprocess.check_output(f'echo {path}/job_{i}/{file_name_base}.json', shell=True)).decode('ascii').strip()\n",
    "        #current_file_path = (subprocess.check_output(f'echo {path}/job_{i}/{file_name_base}_{plane}.json', shell=True)).decode('ascii').strip()\n",
    "        \n",
    "        if os.path.exists(current_file_path):\n",
    "            job_files_list.append(current_file_path)\n",
    "        else:\n",
    "            print(f'Job {i} failed')\n",
    "    \n",
    "    print(f'{n_jobs_succeeded} out of a total of {n_jobs} succeeded')\n",
    "    if n_jobs_succeeded != len(job_files_list):\n",
    "        print('ERROR: not all succeeded jobs paths were retrieved')\n",
    "        \n",
    "    return job_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = Path('/eos/user/l/lpauwels/ht_condor_sps_tracking_results/tidvg_studies/aperture_measurements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = {\n",
    "    'delta_gap0.0': Path(dir_path, 'delta_gap_0.0'),\n",
    "    'delta_gap0.1': Path(dir_path, 'delta_gap_0.1'),\n",
    "    'delta_gap0.2': Path(dir_path, 'delta_gap_0.2'),\n",
    "    'delta_gap0.3': Path(dir_path, 'delta_gap_0.3'),\n",
    "    'delta_gap0.4': Path(dir_path, 'delta_gap_0.4'),\n",
    "    'delta_gap0.5': Path(dir_path, 'delta_gap_0.5'),\n",
    "    'delta_gap0.6': Path(dir_path, 'delta_gap_0.6'),\n",
    "    'delta_gap0.7': Path(dir_path, 'delta_gap_0.7'),\n",
    "    'delta_gap0.8': Path(dir_path, 'delta_gap_0.8'),\n",
    "    'delta_gap0.9': Path(dir_path, 'delta_gap_0.9'),\n",
    "    'delta_gap1.0': Path(dir_path, 'delta_gap_1.0'),\n",
    "    'delta_gap1.1': Path(dir_path, 'delta_gap_1.1'),\n",
    "    'delta_gap1.2': Path(dir_path, 'delta_gap_1.2'),\n",
    "    'delta_gap1.3': Path(dir_path, 'delta_gap_1.3'),\n",
    "    'delta_gap1.4': Path(dir_path, 'delta_gap_1.4'),\n",
    "    'delta_gap1.5': Path(dir_path, 'delta_gap_1.5'),\n",
    "    'delta_gap1.6': Path(dir_path, 'delta_gap_1.6'),\n",
    "    'delta_gap1.7': Path(dir_path, 'delta_gap_1.7'),\n",
    "    'delta_gap1.8': Path(dir_path, 'delta_gap_1.8'),\n",
    "    'delta_gap1.9': Path(dir_path, 'delta_gap_1.9'),\n",
    "    'delta_gap2.0': Path(dir_path, 'delta_gap_2.0'),\n",
    "    'delta_gap2.1': Path(dir_path, 'delta_gap_2.1'),\n",
    "    'delta_gap2.2': Path(dir_path, 'delta_gap_2.2'),\n",
    "    'delta_gap2.3': Path(dir_path, 'delta_gap_2.3'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "Job 21 failed\n",
      "Job 28 failed\n",
      "78 out of a total of 80 succeeded\n",
      "Job 21 failed\n",
      "Job 28 failed\n",
      "78 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "Job 47 failed\n",
      "79 out of a total of 80 succeeded\n",
      "Job 47 failed\n",
      "79 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n",
      "80 out of a total of 80 succeeded\n"
     ]
    }
   ],
   "source": [
    "lm_paths = {}\n",
    "for delta_gap in subdirs:\n",
    "    lm_paths[delta_gap] = {}\n",
    "    lm_paths[delta_gap]['linear'] = get_lossmap_paths(subdirs[delta_gap], f'LM_linear_{delta_gap}')\n",
    "    lm_paths[delta_gap]['ripple'] = get_lossmap_paths(subdirs[delta_gap], f'LM_ripple_{delta_gap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_gap0.0_ripple\n",
      "delta_gap0.0_linear\n",
      "delta_gap0.1_ripple\n",
      "delta_gap0.1_linear\n",
      "delta_gap0.2_ripple\n",
      "delta_gap0.2_linear\n",
      "delta_gap0.3_ripple\n",
      "delta_gap0.3_linear\n",
      "delta_gap0.4_ripple\n",
      "delta_gap0.4_linear\n",
      "delta_gap0.5_ripple\n",
      "delta_gap0.5_linear\n",
      "delta_gap0.6_ripple\n",
      "delta_gap0.6_linear\n",
      "delta_gap0.7_ripple\n",
      "delta_gap0.7_linear\n",
      "delta_gap0.8_ripple\n",
      "delta_gap0.8_linear\n",
      "delta_gap0.9_ripple\n",
      "delta_gap0.9_linear\n",
      "delta_gap1.0_ripple\n",
      "delta_gap1.0_linear\n",
      "delta_gap1.1_ripple\n",
      "delta_gap1.1_linear\n",
      "delta_gap1.2_ripple\n",
      "delta_gap1.2_linear\n",
      "delta_gap1.3_ripple\n",
      "delta_gap1.3_linear\n",
      "delta_gap1.4_ripple\n",
      "delta_gap1.4_linear\n",
      "delta_gap1.5_ripple\n",
      "delta_gap1.5_linear\n",
      "delta_gap1.6_ripple\n",
      "delta_gap1.6_linear\n",
      "delta_gap1.7_ripple\n",
      "delta_gap1.7_linear\n",
      "delta_gap1.8_ripple\n",
      "delta_gap1.8_linear\n",
      "delta_gap1.9_ripple\n",
      "delta_gap1.9_linear\n",
      "delta_gap2.0_ripple\n",
      "delta_gap2.0_linear\n",
      "delta_gap2.1_ripple\n",
      "delta_gap2.1_linear\n",
      "delta_gap2.2_ripple\n",
      "delta_gap2.2_linear\n",
      "delta_gap2.3_ripple\n",
      "delta_gap2.3_linear\n"
     ]
    }
   ],
   "source": [
    "combined_data = {}\n",
    "\n",
    "for delta_gap in subdirs:\n",
    "    for sim_type in ['ripple', 'linear']:\n",
    "        print(f'{delta_gap}_{sim_type}')\n",
    "        \n",
    "        loc_dic = {\n",
    "            'collimator': {'s': [], 'name': [], 'length': [], 'n': []},\n",
    "            'aperture': {'s': [], 'name': [], 'n': []},\n",
    "            'machine_length': 6911.5038,\n",
    "            'interpolation': 0.1,\n",
    "            'reversed': False\n",
    "        }\n",
    "\n",
    "        collimator_dict = {}  # To sum losses correctly\n",
    "        aperture_dict = {}    # To sum losses correctly\n",
    "\n",
    "        for file_path in lm_paths[delta_gap][sim_type]:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # --- Merge collimator data ---\n",
    "            for i in range(len(data['collimator']['s'])):\n",
    "                key = (data['collimator']['s'][i], data['collimator']['name'][i])\n",
    "                if key in collimator_dict:\n",
    "                    collimator_dict[key][\"n\"] += data['collimator']['n'][i]\n",
    "                else:\n",
    "                    collimator_dict[key] = {\n",
    "                        \"s\": data['collimator']['s'][i],\n",
    "                        \"name\": data['collimator']['name'][i],\n",
    "                        \"length\": data['collimator']['length'][i],\n",
    "                        \"n\": data['collimator']['n'][i]\n",
    "                    }\n",
    "\n",
    "            # --- Merge aperture data ---\n",
    "            for i in range(len(data['aperture']['s'])):\n",
    "                key = (data['aperture']['s'][i], data['aperture']['name'][i])\n",
    "                if key in aperture_dict:\n",
    "                    aperture_dict[key][\"n\"] += data['aperture']['n'][i]\n",
    "                else:\n",
    "                    aperture_dict[key] = {\n",
    "                        \"s\": data['aperture']['s'][i],\n",
    "                        \"name\": data['aperture']['name'][i],\n",
    "                        \"n\": data['aperture']['n'][i]\n",
    "                    }\n",
    "\n",
    "        # Convert collimator dictionary back to lists\n",
    "        sorted_collimator = sorted(collimator_dict.values(), key=lambda x: x[\"s\"])\n",
    "        loc_dic['collimator']['s'] = [entry[\"s\"] for entry in sorted_collimator]\n",
    "        loc_dic['collimator']['name'] = [entry[\"name\"] for entry in sorted_collimator]\n",
    "        loc_dic['collimator']['length'] = [entry[\"length\"] for entry in sorted_collimator]\n",
    "        loc_dic['collimator']['n'] = [entry[\"n\"] for entry in sorted_collimator]\n",
    "\n",
    "        # Convert aperture dictionary back to lists\n",
    "        sorted_aperture = sorted(aperture_dict.values(), key=lambda x: x[\"s\"])\n",
    "        loc_dic['aperture']['s'] = [entry[\"s\"] for entry in sorted_aperture]\n",
    "        loc_dic['aperture']['name'] = [entry[\"name\"] for entry in sorted_aperture]\n",
    "        loc_dic['aperture']['n'] = [entry[\"n\"] for entry in sorted_aperture]\n",
    "\n",
    "        combined_data[f'{delta_gap}_{sim_type}'] = loc_dic\n",
    "        with open(f'tidvg_studies/aperture_measurements/combined_jsons/{delta_gap}_{sim_type}.json', 'w') as f:\n",
    "            json.dump(loc_dic, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xsuite_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
